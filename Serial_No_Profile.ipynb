{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymongo\n",
    "from tabulate import tabulate\n",
    "\n",
    "# MongoDB Connection\n",
    "def connect_to_mongo():\n",
    "    # Replace with your MongoDB connection details\n",
    "    client = pymongo.MongoClient(\n",
    "        'mongodb+srv://SkyrichSolutions:admin@skyrich-solutions.4hwg7.mongodb.net/?retryWrites=true&w=majority&appName=SkyRich-Solutions'\n",
    "    )\n",
    "    db = client['Skyrich-Unprocessed']  # Replace with your database name\n",
    "    unprocessed_collection = db['UnProcessed v1']  # Collection for unprocessed data\n",
    "    processed_collection = db['Processed v1']  # Collection for processed data\n",
    "    return unprocessed_collection, processed_collection\n",
    "\n",
    "# Function to load data from MongoDB's UnprocessedData collection\n",
    "def load_data_from_mongo():\n",
    "    unprocessed_collection, _ = connect_to_mongo()\n",
    "    cursor = unprocessed_collection.find()  # Retrieve all documents\n",
    "    data_list = list(cursor)\n",
    "    df = pd.DataFrame(data_list)\n",
    "    df.drop(columns=['_id'], inplace=True, errors='ignore')  # Drop the _id field\n",
    "    return df\n",
    "\n",
    "# Load the unprocessed data into a DataFrame\n",
    "Part_Analysis = load_data_from_mongo()\n",
    "\n",
    "# Display the shape of the DataFrame\n",
    "print(\"Part Data shape:\", Part_Analysis.shape)\n",
    "\n",
    "# Print the count of documents in the UnProcessed collection\n",
    "unprocessed_collection, _ = connect_to_mongo()\n",
    "unprocessed_data_count = unprocessed_collection.count_documents({})\n",
    "print(f\"\\nNumber of Rows in the unprocessed data collection: {unprocessed_data_count}\")\n",
    "\n",
    "# Display the unprocessed DataFrame in tabular format\n",
    "print(\"\\nUnprocessed DataFrame:\")\n",
    "print(tabulate(Part_Analysis, headers='keys', tablefmt='psql'))\n",
    "\n",
    "# Define the serial number profiles that should be labeled as \"Replacement part B\"\n",
    "serial_no_profiles = ['ZPP2', 'ZPP8', 'ZCS1']\n",
    "\n",
    "# Add a 'Violation' column to flag rows that are discrepancies\n",
    "Part_Analysis['Violation'] = (\n",
    "    (Part_Analysis['Serial_No_Profile'].isin(serial_no_profiles)) & \n",
    "    (Part_Analysis['Replacement_Part'] != 'B')\n",
    ").astype(int)  # 1 = Violation, 0 = No Violation\n",
    "\n",
    "# Calculate the total number of violations in the DataFrame\n",
    "total_violations = Part_Analysis['Violation'].sum()\n",
    "print(f\"\\nTotal number of violations in the DataFrame: {total_violations}\")\n",
    "\n",
    "# Extract rows with violations\n",
    "discrepancies = Part_Analysis[Part_Analysis['Violation'] == 1]\n",
    "\n",
    "if not discrepancies.empty:\n",
    "    # Add a Row ID column (+2 offset)\n",
    "    discrepancies['Row ID'] = discrepancies.index + 2\n",
    "\n",
    "    # Rearrange columns to place 'Row ID' as the first column\n",
    "    columns = ['Row ID'] + [col for col in discrepancies.columns if col != 'Row ID']\n",
    "    discrepancies = discrepancies[columns]\n",
    "\n",
    "    # Display the discrepancies\n",
    "    print(\"\\nDiscrepancies in the data:\")\n",
    "    print(tabulate(discrepancies, headers='keys', tablefmt='psql'))\n",
    "else:\n",
    "    print(\"\\nNo discrepancies detected in the data set.\")\n",
    "\n",
    "# Process the data: Resolve discrepancies\n",
    "processed_Part_Analysis = Part_Analysis.copy()\n",
    "\n",
    "# Update the 'Replacement Part' column to 'B' for rows with discrepancies\n",
    "processed_Part_Analysis.loc[\n",
    "    (processed_Part_Analysis['Serial_No_Profile'].isin(serial_no_profiles)) & \n",
    "    (processed_Part_Analysis['Replacement_Part'] != 'B'),\n",
    "    'Replacement_Part'\n",
    "] = 'B'\n",
    "\n",
    "# Verify Resolutions: Check for any remaining discrepancies\n",
    "remaining_discrepancies = processed_Part_Analysis[\n",
    "    (processed_Part_Analysis['Serial_No_Profile'].isin(serial_no_profiles)) & \n",
    "    (processed_Part_Analysis['Replacement_Part'] != 'B')\n",
    "]\n",
    "\n",
    "if remaining_discrepancies.empty:\n",
    "    print(\"\\nAll discrepancies have been resolved in the processed data.\")\n",
    "else:\n",
    "    print(\"\\nRemaining discrepancies in the processed data:\")\n",
    "    print(tabulate(remaining_discrepancies, headers='keys', tablefmt='psql'))\n",
    "\n",
    "# Display the processed DataFrame in tabular format\n",
    "print(\"\\nProcessed DataFrame:\")\n",
    "print(tabulate(processed_Part_Analysis, headers='keys', tablefmt='psql'))\n",
    "\n",
    "# Insert the processed data into MongoDB (Processed v1 collection)\n",
    "_, processed_collection = connect_to_mongo()  # Get only the processed collection\n",
    "processed_collection.delete_many({})  # Clear previous data in the processed collection\n",
    "processed_collection.insert_many(processed_Part_Analysis.to_dict('records'))\n",
    "\n",
    "print(\"\\nProcessed data has been exported to MongoDB's 'Processed v1' collection.\")\n",
    "\n",
    "# Optional: Verify processed data count in MongoDB\n",
    "processed_data_count = processed_collection.count_documents({})\n",
    "print(f\"\\nNumber of Rows in the processed data collection: {processed_data_count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
